"use strict";(self.webpackChunkmy_website=self.webpackChunkmy_website||[]).push([[976],{2053:(e,t,s)=>{s.r(t),s.d(t,{assets:()=>c,contentTitle:()=>o,default:()=>h,frontMatter:()=>d,metadata:()=>r,toc:()=>l});const r=JSON.parse('{"id":"intro","title":"Introduction","description":"Overview","source":"@site/docs/intro.md","sourceDirName":".","slug":"/intro","permalink":"/elsai_arms_docs/docs/intro","draft":false,"unlisted":false,"tags":[],"version":"current","sidebarPosition":1,"frontMatter":{"sidebar_position":1},"sidebar":"tutorialSidebar","next":{"title":"Getting Started","permalink":"/elsai_arms_docs/docs/category/getting-started"}}');var n=s(4848),i=s(8453);const d={sidebar_position:1},o="Introduction",c={},l=[{value:"Overview",id:"overview",level:2},{value:"Elsai Agent Resource Monitoring System",id:"elsai-agent-resource-monitoring-system",level:2},{value:"Key Features",id:"key-features",level:2},{value:"Project Metrics",id:"project-metrics",level:3},{value:"LLM Metrics",id:"llm-metrics",level:3},{value:"Run Metrics",id:"run-metrics",level:3}];function a(e){const t={h1:"h1",h2:"h2",h3:"h3",header:"header",li:"li",p:"p",strong:"strong",table:"table",tbody:"tbody",td:"td",th:"th",thead:"thead",tr:"tr",ul:"ul",...(0,i.R)(),...e.components};return(0,n.jsxs)(n.Fragment,{children:[(0,n.jsx)(t.header,{children:(0,n.jsx)(t.h1,{id:"introduction",children:"Introduction"})}),"\n",(0,n.jsx)(t.h2,{id:"overview",children:"Overview"}),"\n",(0,n.jsxs)(t.p,{children:[(0,n.jsx)(t.strong,{children:"Elsai ARMS (Agent Resource Management System)"})," is a backend framework designed to monitor and manage the usage, cost, and performance of AI-powered projects using large language models. It provides centralized tracking for token consumption, execution metrics, and cost analysis, making it ideal for teams running multiple AI agents or pipelines. By storing data in MongoDB and supporting exportable JSON reports, it enables easy integration with analytics or observability tools."]}),"\n",(0,n.jsx)(t.h2,{id:"elsai-agent-resource-monitoring-system",children:"Elsai Agent Resource Monitoring System"}),"\n",(0,n.jsx)(t.p,{children:"Elsai ARMS is a lightweight monitoring and cost-tracking system for LLM-based agents and applications. Designed for observability, it enables project-based tracking and reporting. It is a modular telemetry and monitoring framework designed to track LLM usage, performance, and cost metrics in real-time. At its core, it integrates with OpenTelemetry via the TelemetryWrapper to log token usage (Token Metrics), latency (LLM Monitor), and estimated costs (Cost Metrics). Projects are managed using a Project Manager that interfaces with MongoDB for persistent storage, while an Exporter module serializes the logged data into JSON for reporting."}),"\n",(0,n.jsx)(t.h2,{id:"key-features",children:"Key Features"}),"\n",(0,n.jsxs)(t.ul,{children:["\n",(0,n.jsx)(t.li,{children:"Token usage tracking"}),"\n",(0,n.jsx)(t.li,{children:"Cost tracking"}),"\n",(0,n.jsx)(t.li,{children:"Execution logs"}),"\n",(0,n.jsx)(t.li,{children:"Performance metrics"}),"\n",(0,n.jsx)(t.li,{children:"LLM Monitoring"}),"\n",(0,n.jsx)(t.li,{children:"Success/error analysis"}),"\n"]}),"\n",(0,n.jsx)(t.h3,{id:"project-metrics",children:"Project Metrics"}),"\n",(0,n.jsxs)(t.table,{children:[(0,n.jsx)(t.thead,{children:(0,n.jsxs)(t.tr,{children:[(0,n.jsx)(t.th,{children:"Field"}),(0,n.jsx)(t.th,{children:"Description"})]})}),(0,n.jsxs)(t.tbody,{children:[(0,n.jsxs)(t.tr,{children:[(0,n.jsx)(t.td,{children:(0,n.jsx)(t.strong,{children:"Time of Creation"})}),(0,n.jsx)(t.td,{children:"Timestamp when the project or a processing run was initiated."})]}),(0,n.jsxs)(t.tr,{children:[(0,n.jsx)(t.td,{children:(0,n.jsx)(t.strong,{children:"Total Tokens"})}),(0,n.jsx)(t.td,{children:"Cumulative sum of tokens processed (input + output) across all runs."})]}),(0,n.jsxs)(t.tr,{children:[(0,n.jsx)(t.td,{children:(0,n.jsx)(t.strong,{children:"Total Cost per Model"})}),(0,n.jsx)(t.td,{children:"Aggregated cost grouped by model (e.g., GPT-4, Claude, etc.)"})]}),(0,n.jsxs)(t.tr,{children:[(0,n.jsx)(t.td,{children:(0,n.jsx)(t.strong,{children:"Average Frequency"})}),(0,n.jsx)(t.td,{children:"Average number of runs per day/hour/week."})]}),(0,n.jsxs)(t.tr,{children:[(0,n.jsx)(t.td,{children:(0,n.jsx)(t.strong,{children:"Success Rate"})}),(0,n.jsx)(t.td,{children:"Percentage of successful runs out of all runs."})]}),(0,n.jsxs)(t.tr,{children:[(0,n.jsx)(t.td,{children:(0,n.jsx)(t.strong,{children:"Number of Successful Runs"})}),(0,n.jsx)(t.td,{children:"Total number of runs that ended successfully (no crash)."})]})]})]}),"\n",(0,n.jsx)(t.h3,{id:"llm-metrics",children:"LLM Metrics"}),"\n",(0,n.jsxs)(t.table,{children:[(0,n.jsx)(t.thead,{children:(0,n.jsxs)(t.tr,{children:[(0,n.jsx)(t.th,{children:"Field"}),(0,n.jsx)(t.th,{children:"Description"})]})}),(0,n.jsxs)(t.tbody,{children:[(0,n.jsxs)(t.tr,{children:[(0,n.jsx)(t.td,{children:(0,n.jsx)(t.strong,{children:"Model"})}),(0,n.jsx)(t.td,{children:"Name of the model used (e.g., gpt-4, claude-3-sonnet)."})]}),(0,n.jsxs)(t.tr,{children:[(0,n.jsx)(t.td,{children:(0,n.jsx)(t.strong,{children:"Input Tokens"})}),(0,n.jsx)(t.td,{children:"Number of tokens in the prompt sent to the LLM."})]}),(0,n.jsxs)(t.tr,{children:[(0,n.jsx)(t.td,{children:(0,n.jsx)(t.strong,{children:"Output Tokens"})}),(0,n.jsx)(t.td,{children:"Number of tokens generated by the LLM in the response."})]}),(0,n.jsxs)(t.tr,{children:[(0,n.jsx)(t.td,{children:(0,n.jsx)(t.strong,{children:"Total Tokens"})}),(0,n.jsx)(t.td,{children:"Sum of input and output tokens."})]}),(0,n.jsxs)(t.tr,{children:[(0,n.jsx)(t.td,{children:(0,n.jsx)(t.strong,{children:"Latency"})}),(0,n.jsx)(t.td,{children:"Time taken from request to response (in ms)."})]}),(0,n.jsxs)(t.tr,{children:[(0,n.jsx)(t.td,{children:(0,n.jsx)(t.strong,{children:"Prompt"})}),(0,n.jsx)(t.td,{children:"The actual prompt sent to the LLM."})]}),(0,n.jsxs)(t.tr,{children:[(0,n.jsx)(t.td,{children:(0,n.jsx)(t.strong,{children:"Response"})}),(0,n.jsx)(t.td,{children:"The LLM\u2019s generated response."})]}),(0,n.jsxs)(t.tr,{children:[(0,n.jsx)(t.td,{children:(0,n.jsx)(t.strong,{children:"Cost"})}),(0,n.jsx)(t.td,{children:"Calculated cost for this call, based on token pricing of the model."})]})]})]}),"\n",(0,n.jsx)(t.h3,{id:"run-metrics",children:"Run Metrics"}),"\n",(0,n.jsxs)(t.table,{children:[(0,n.jsx)(t.thead,{children:(0,n.jsxs)(t.tr,{children:[(0,n.jsx)(t.th,{children:"Field"}),(0,n.jsx)(t.th,{children:"Description"})]})}),(0,n.jsxs)(t.tbody,{children:[(0,n.jsxs)(t.tr,{children:[(0,n.jsx)(t.td,{children:(0,n.jsx)(t.strong,{children:"LLM Details"})}),(0,n.jsx)(t.td,{children:"Summary of all LLM calls made in this run (can include model, tokens, cost)."})]}),(0,n.jsxs)(t.tr,{children:[(0,n.jsx)(t.td,{children:(0,n.jsx)(t.strong,{children:"Custom Metrics"})}),(0,n.jsx)(t.td,{children:"User-defined values like accuracy, classification labels, relevance score, etc."})]}),(0,n.jsxs)(t.tr,{children:[(0,n.jsx)(t.td,{children:(0,n.jsx)(t.strong,{children:"Logs"})}),(0,n.jsx)(t.td,{children:"Event logs or trace logs emitted during the run (info, warning, error). May include stages, retries, failures, etc."})]}),(0,n.jsxs)(t.tr,{children:[(0,n.jsx)(t.td,{children:(0,n.jsx)(t.strong,{children:"Start Time"})}),(0,n.jsx)(t.td,{children:"The exact timestamp when the run or process began execution."})]}),(0,n.jsxs)(t.tr,{children:[(0,n.jsx)(t.td,{children:(0,n.jsx)(t.strong,{children:"End Time"})}),(0,n.jsx)(t.td,{children:"The exact timestamp when the run or process completed execution."})]}),(0,n.jsxs)(t.tr,{children:[(0,n.jsx)(t.td,{children:(0,n.jsx)(t.strong,{children:"Execution Duration"})}),(0,n.jsx)(t.td,{children:"The total time taken from the start to the end of the run, typically measured in seconds ."})]}),(0,n.jsxs)(t.tr,{children:[(0,n.jsx)(t.td,{children:(0,n.jsx)(t.strong,{children:"Success Status"})}),(0,n.jsx)(t.td,{children:"Boolean or enum (SUCCESS, FAILED) indicating whether the run met its goal."})]})]})]})]})}function h(e={}){const{wrapper:t}={...(0,i.R)(),...e.components};return t?(0,n.jsx)(t,{...e,children:(0,n.jsx)(a,{...e})}):a(e)}},8453:(e,t,s)=>{s.d(t,{R:()=>d,x:()=>o});var r=s(6540);const n={},i=r.createContext(n);function d(e){const t=r.useContext(i);return r.useMemo((function(){return"function"==typeof e?e(t):{...t,...e}}),[t,e])}function o(e){let t;return t=e.disableParentContext?"function"==typeof e.components?e.components(n):e.components||n:d(e.components),r.createElement(i.Provider,{value:t},e.children)}}}]);